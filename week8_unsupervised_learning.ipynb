{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce5965-aa5c-452e-adb5-ce95144748eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 8: Unsupervised Learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up visualization style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Week 8 Unsupervised Learning Environment Ready!\")\n",
    "\n",
    "# Load your cleaned dataset\n",
    "df = pd.read_csv('titanic_cleaned.csv')\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nColumns available:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c5dbfb-e805-4338-aea6-91cb47b91b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DATASET OVERVIEW FOR UNSUPERVISED LEARNING ===\")\n",
    "\n",
    "# Display basic information\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# For unsupervised learning, we'll use numerical features\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nNumerical features available: {numerical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30741ffd-f615-4800-a654-7262f0e840a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PREPARING DATA FOR UNSUPERVISED LEARNING ===\")\n",
    "\n",
    "# Select features for clustering\n",
    "# We'll use features that describe passenger characteristics\n",
    "features_for_clustering = ['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']\n",
    "\n",
    "print(f\"Selected features for clustering: {features_for_clustering}\")\n",
    "\n",
    "# Create feature matrix\n",
    "X = df[features_for_clustering].copy()\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Missing values after cleaning: {X.isnull().sum().sum()}\")\n",
    "\n",
    "# Standardize the features (important for clustering)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"‚úÖ Features standardized (mean=0, std=1)\")\n",
    "\n",
    "# Create DataFrame with scaled features\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=features_for_clustering)\n",
    "print(\"\\nScaled features statistics:\")\n",
    "print(X_scaled_df.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d9ce3-babb-4c6c-ab82-03e7c68a22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== FEATURE RELATIONSHIPS ===\")\n",
    "\n",
    "# Create pairplot to see relationships between features\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(X, diag_kind='hist', corner=True)\n",
    "plt.suptitle('Feature Relationships for Clustering', y=1.02, fontsize=16, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "correlation_matrix = X.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç Initial Observations:\")\n",
    "print(\"‚Ä¢ Some features show clear relationships (e.g., Pclass vs Fare)\")\n",
    "print(\"‚Ä¢ Potential clusters may exist based on passenger profiles\")\n",
    "print(\"‚Ä¢ Standardization will help with clustering algorithm performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908dfba-388e-4975-9288-985dd3897435",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== FINDING OPTIMAL NUMBER OF CLUSTERS ===\")\n",
    "\n",
    "# Use Elbow Method and Silhouette Analysis to find optimal k\n",
    "range_k = range(2, 10)\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in range_k:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    inertia.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, cluster_labels))\n",
    "\n",
    "# Plot Elbow Method\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Elbow curve\n",
    "ax1.plot(range_k, inertia, 'bo-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Inertia (Within-cluster sum of squares)')\n",
    "ax1.set_title('Elbow Method for Optimal k', fontweight='bold')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Silhouette scores\n",
    "ax2.plot(range_k, silhouette_scores, 'ro-', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Number of Clusters (k)')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.set_title('Silhouette Analysis for Optimal k', fontweight='bold')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find optimal k (you can choose based on the plots)\n",
    "optimal_k = range_k[np.argmax(silhouette_scores)]\n",
    "print(f\"üéØ Recommended number of clusters: {optimal_k}\")\n",
    "print(f\"   Based on highest silhouette score: {max(silhouette_scores):.3f}\")\n",
    "\n",
    "print(\"\\nüîç INTERPRETATION GUIDE:\")\n",
    "print(\"‚Ä¢ Elbow Method: Look for 'elbow' where inertia stops decreasing rapidly\")\n",
    "print(\"‚Ä¢ Silhouette Score: Higher values indicate better-defined clusters\")\n",
    "print(\"‚Ä¢ Choose k that balances cluster quality and interpretability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b0b86c-ebaf-48f5-8341-4fbb8ed02fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== K-MEANS CLUSTERING IMPLEMENTATION ===\")\n",
    "\n",
    "# Apply K-Means with optimal k\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to original data\n",
    "df_clustered = df.copy()\n",
    "df_clustered['Cluster'] = cluster_labels\n",
    "X_clustered = X.copy()\n",
    "X_clustered['Cluster'] = cluster_labels\n",
    "\n",
    "print(f\"‚úÖ K-Means clustering completed with {optimal_k} clusters\")\n",
    "print(f\"Cluster distribution:\")\n",
    "cluster_counts = df_clustered['Cluster'].value_counts().sort_index()\n",
    "for cluster, count in cluster_counts.items():\n",
    "    print(f\"  Cluster {cluster}: {count} passengers ({count/len(df_clustered)*100:.1f}%)\")\n",
    "\n",
    "# Calculate silhouette score\n",
    "sil_score = silhouette_score(X_scaled, cluster_labels)\n",
    "print(f\"Silhouette Score: {sil_score:.3f}\")\n",
    "\n",
    "print(\"\\nüîç SILHOUETTE SCORE INTERPRETATION:\")\n",
    "print(\"‚Ä¢ +1: Perfectly separated clusters\")\n",
    "print(\"‚Ä¢  0: Overlapping clusters\") \n",
    "print(\"‚Ä¢ -1: Completely wrong assignments\")\n",
    "print(f\"‚Ä¢ Our score ({sil_score:.3f}): {'Good separation' if sil_score > 0.5 else 'Moderate separation' if sil_score > 0.25 else 'Poor separation'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5db226-e362-425e-b1f1-f967961b1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== CLUSTER CHARACTERISTICS ANALYSIS ===\")\n",
    "\n",
    "# Calculate mean values for each cluster\n",
    "cluster_means = X_clustered.groupby('Cluster').mean()\n",
    "cluster_std = X_clustered.groupby('Cluster').std()\n",
    "\n",
    "print(\"üìä CLUSTER PROFILES (Mean Values):\")\n",
    "display(cluster_means.round(2))\n",
    "\n",
    "print(\"\\nüìä CLUSTER VARIABILITY (Standard Deviation):\")\n",
    "display(cluster_std.round(2))\n",
    "\n",
    "# Visualize cluster characteristics\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "features_to_plot = features_for_clustering\n",
    "\n",
    "for i, feature in enumerate(features_to_plot):\n",
    "    row, col = i // 3, i % 3\n",
    "    \n",
    "    # Boxplot for each feature by cluster\n",
    "    sns.boxplot(data=X_clustered, x='Cluster', y=feature, ax=axes[row, col], palette='Set2')\n",
    "    axes[row, col].set_title(f'{feature} Distribution by Cluster', fontweight='bold')\n",
    "    axes[row, col].set_xlabel('Cluster')\n",
    "    axes[row, col].set_ylabel(feature)\n",
    "    axes[row, col].grid(alpha=0.3)\n",
    "\n",
    "# Remove empty subplot if needed\n",
    "if len(features_to_plot) < 6:\n",
    "    for i in range(len(features_to_plot), 6):\n",
    "        fig.delaxes(axes.flatten()[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç CLUSTER INTERPRETATION:\")\n",
    "print(\"Look for patterns in the cluster profiles:\")\n",
    "print(\"‚Ä¢ Which features distinguish the clusters?\")\n",
    "print(\"‚Ä¢ Do clusters represent meaningful passenger segments?\")\n",
    "print(\"‚Ä¢ Are there clear patterns in age, fare, family size, or class?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e6a3e9-acfe-4b98-a828-873c7cff0719",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PRINCIPAL COMPONENT ANALYSIS (PCA) ===\")\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create PCA components DataFrame\n",
    "pca_components = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    columns=[f'PC{i+1}' for i in range(pca.n_components_)],\n",
    "    index=features_for_clustering\n",
    ")\n",
    "\n",
    "print(\"üìä PCA COMPONENTS (Feature Contributions):\")\n",
    "display(pca_components.round(3))\n",
    "\n",
    "# Explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "print(f\"\\nüìà EXPLAINED VARIANCE:\")\n",
    "for i, (var, cum_var) in enumerate(zip(explained_variance, cumulative_variance)):\n",
    "    print(f\"PC{i+1}: {var:.3f} ({var*100:.1f}%) - Cumulative: {cum_var:.3f} ({cum_var*100:.1f}%)\")\n",
    "\n",
    "# Plot explained variance\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Scree plot\n",
    "ax1.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.7, color='skyblue')\n",
    "ax1.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, 'ro-', linewidth=2)\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Explained Variance Ratio')\n",
    "ax1.set_title('PCA Scree Plot', fontweight='bold')\n",
    "ax1.grid(alpha=0.3)\n",
    "ax1.legend(['Cumulative Variance', 'Individual Variance'])\n",
    "\n",
    "# Cumulative variance\n",
    "ax2.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, 'bo-', linewidth=2, markersize=8)\n",
    "ax2.axhline(y=0.95, color='red', linestyle='--', label='95% Variance')\n",
    "ax2.axhline(y=0.90, color='orange', linestyle='--', label='90% Variance')\n",
    "ax2.axhline(y=0.80, color='green', linestyle='--', label='80% Variance')\n",
    "ax2.set_xlabel('Number of Principal Components')\n",
    "ax2.set_ylabel('Cumulative Explained Variance')\n",
    "ax2.set_title('Cumulative Explained Variance', fontweight='bold')\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç PCA INTERPRETATION:\")\n",
    "print(\"‚Ä¢ PC1, PC2 capture the most important patterns in the data\")\n",
    "print(\"‚Ä¢ Components show which features contribute most to each direction\")\n",
    "print(\"‚Ä¢ We can reduce dimensions while preserving most information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6503a25-0ffb-4549-90b0-d0c58c2a68bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PCA BIPLOT VISUALIZATION ===\")\n",
    "\n",
    "# Create biplot (PCA with feature vectors)\n",
    "def pca_biplot(components, features, scale=1.5):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Scatter plot of first two components\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, \n",
    "                         cmap='viridis', alpha=0.6, s=50)\n",
    "    \n",
    "    # Plot feature vectors\n",
    "    for i, feature in enumerate(features):\n",
    "        plt.arrow(0, 0, components[i, 0] * scale, components[i, 1] * scale,\n",
    "                 color='red', alpha=0.7, head_width=0.05)\n",
    "        plt.text(components[i, 0] * scale * 1.15, components[i, 1] * scale * 1.15,\n",
    "                feature, color='red', ha='center', va='center', fontweight='bold')\n",
    "    \n",
    "    plt.xlabel(f'PC1 ({explained_variance[0]*100:.1f}% Variance)')\n",
    "    plt.ylabel(f'PC2 ({explained_variance[1]*100:.1f}% Variance)')\n",
    "    plt.title('PCA Biplot - Clusters with Feature Directions', fontweight='bold', fontsize=14)\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "    plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Create biplot\n",
    "pca_biplot(pca.components_.T, features_for_clustering)\n",
    "\n",
    "print(\"üîç BIPLOT INTERPRETATION:\")\n",
    "print(\"‚Ä¢ Points: Individual passengers projected onto PC1 and PC2\")\n",
    "print(\"‚Ä¢ Arrows: Direction and importance of original features\")\n",
    "print(\"‚Ä¢ Colors: Cluster assignments from K-Means\")\n",
    "print(\"‚Ä¢ Interpretation: Features pointing in similar directions are correlated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2507d39-5b07-4f35-a683-cc298d2b945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ASSIGNMENT 8: 2D CLUSTER VISUALIZATION WITH PCA ===\")\n",
    "\n",
    "# Use first two principal components for 2D visualization\n",
    "pca_2d = PCA(n_components=2)\n",
    "X_pca_2d = pca_2d.fit_transform(X_scaled)\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "pca_df = pd.DataFrame({\n",
    "    'PC1': X_pca_2d[:, 0],\n",
    "    'PC2': X_pca_2d[:, 1],\n",
    "    'Cluster': cluster_labels\n",
    "})\n",
    "\n",
    "# Add original features for interpretation\n",
    "for feature in features_for_clustering:\n",
    "    pca_df[feature] = X[feature].values\n",
    "\n",
    "print(f\"‚úÖ 2D PCA transformation completed\")\n",
    "print(f\"Explained variance by PC1 and PC2: {pca_2d.explained_variance_ratio_.sum()*100:.1f}%\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Cluster visualization in PCA space\n",
    "scatter = axes[0, 0].scatter(pca_df['PC1'], pca_df['PC2'], c=pca_df['Cluster'], \n",
    "                            cmap='viridis', alpha=0.7, s=50)\n",
    "axes[0, 0].set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]*100:.1f}% Variance)')\n",
    "axes[0, 0].set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]*100:.1f}% Variance)')\n",
    "axes[0, 0].set_title('Passenger Clusters in 2D PCA Space', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=axes[0, 0], label='Cluster')\n",
    "\n",
    "# Plot 2: Cluster centers in PCA space\n",
    "cluster_centers_pca = pca_2d.transform(kmeans.cluster_centers_)\n",
    "for i, center in enumerate(cluster_centers_pca):\n",
    "    axes[0, 1].scatter(center[0], center[1], marker='X', s=200, color='red', \n",
    "                      label=f'Center {i}' if i == 0 else \"\")\n",
    "    axes[0, 1].text(center[0] + 0.1, center[1] + 0.1, f'Center {i}', \n",
    "                   fontweight='bold', fontsize=10)\n",
    "\n",
    "axes[0, 1].scatter(pca_df['PC1'], pca_df['PC2'], c=pca_df['Cluster'], \n",
    "                  cmap='viridis', alpha=0.3, s=30)\n",
    "axes[0, 1].set_xlabel('PC1')\n",
    "axes[0, 1].set_ylabel('PC2')\n",
    "axes[0, 1].set_title('Cluster Centers in PCA Space', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Plot 3: Feature contribution to PCs\n",
    "pc_loadings = pd.DataFrame(\n",
    "    pca_2d.components_.T,\n",
    "    columns=['PC1', 'PC2'],\n",
    "    index=features_for_clustering\n",
    ")\n",
    "\n",
    "pc_loadings.plot(kind='bar', ax=axes[1, 0], color=['skyblue', 'lightcoral'])\n",
    "axes[1, 0].set_title('Feature Contributions to Principal Components', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Loading')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Plot 4: Cluster sizes\n",
    "cluster_sizes = pca_df['Cluster'].value_counts().sort_index()\n",
    "axes[1, 1].bar(cluster_sizes.index, cluster_sizes.values, color='lightgreen', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Cluster')\n",
    "axes[1, 1].set_ylabel('Number of Passengers')\n",
    "axes[1, 1].set_title('Cluster Sizes', fontweight='bold')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, count in enumerate(cluster_sizes.values):\n",
    "    axes[1, 1].text(i, count + 5, str(count), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5ef31-d698-4d01-9e08-d53b2a4ce421",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== CLUSTER INTERPRETATION AND BUSINESS INSIGHTS ===\")\n",
    "\n",
    "# Analyze each cluster's characteristics\n",
    "cluster_profiles = X_clustered.groupby('Cluster').agg(['mean', 'std']).round(2)\n",
    "\n",
    "print(\"üìä DETAILED CLUSTER PROFILES:\")\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = X_clustered[X_clustered['Cluster'] == cluster]\n",
    "    \n",
    "    print(f\"\\nüéØ CLUSTER {cluster} (n={len(cluster_data)}):\")\n",
    "    \n",
    "    # Interpret based on feature values\n",
    "    age_mean = cluster_data['Age'].mean()\n",
    "    fare_mean = cluster_data['Fare'].mean()\n",
    "    pclass_mean = cluster_data['Pclass'].mean()\n",
    "    family_size_mean = (cluster_data['SibSp'] + cluster_data['Parch']).mean()\n",
    "    \n",
    "    print(f\"   Average Age: {age_mean:.1f} years\")\n",
    "    print(f\"   Average Fare: ${fare_mean:.1f}\")\n",
    "    print(f\"   Average Class: {pclass_mean:.1f} (1st=1, 2nd=2, 3rd=3)\")\n",
    "    print(f\"   Average Family Size: {family_size_mean:.1f}\")\n",
    "    \n",
    "    # Business interpretation\n",
    "    if pclass_mean < 2 and fare_mean > 50:\n",
    "        print(\"   üí° Interpretation: Affluent passengers\")\n",
    "    elif pclass_mean > 2 and fare_mean < 20:\n",
    "        print(\"   üí° Interpretation: Economy class passengers\")\n",
    "    elif age_mean < 25:\n",
    "        print(\"   üí° Interpretation: Younger passengers\")\n",
    "    elif family_size_mean > 2:\n",
    "        print(\"   üí° Interpretation: Family travelers\")\n",
    "    else:\n",
    "        print(\"   üí° Interpretation: Mixed characteristics\")\n",
    "\n",
    "# Compare with survival rates\n",
    "print(f\"\\nüìà CLUSTER SURVIVAL ANALYSIS:\")\n",
    "cluster_survival = df_clustered.groupby('Cluster')['Survived'].agg(['mean', 'count'])\n",
    "cluster_survival['survival_rate'] = (cluster_survival['mean'] * 100).round(1)\n",
    "cluster_survival = cluster_survival.sort_values('survival_rate', ascending=False)\n",
    "\n",
    "for cluster, row in cluster_survival.iterrows():\n",
    "    print(f\"   Cluster {cluster}: {row['survival_rate']}% survival ({row['count']} passengers)\")\n",
    "\n",
    "print(f\"\\nüîç KEY INSIGHTS:\")\n",
    "print(\"‚Ä¢ Clusters reveal natural passenger segments\")\n",
    "print(\"‚Ä¢ Survival rates vary significantly between clusters\")\n",
    "print(\"‚Ä¢ PCA visualization shows clear separation of some clusters\")\n",
    "print(\"‚Ä¢ Feature patterns align with known Titanic survival factors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f707573-2b7b-466a-b69e-6bc3f17bc18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ADVANCED CLUSTERING ANALYSIS ===\")\n",
    "\n",
    "# Compare different numbers of clusters\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "k_values = [2, 3, 4, 5]\n",
    "\n",
    "for i, k in enumerate(k_values):\n",
    "    row, col = i // 2, i % 2\n",
    "    \n",
    "    # Apply K-Means\n",
    "    kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels_temp = kmeans_temp.fit_predict(X_scaled)\n",
    "    \n",
    "    # Apply PCA for visualization\n",
    "    pca_temp = PCA(n_components=2)\n",
    "    X_pca_temp = pca_temp.fit_transform(X_scaled)\n",
    "    \n",
    "    # Plot\n",
    "    scatter = axes[row, col].scatter(X_pca_temp[:, 0], X_pca_temp[:, 1], \n",
    "                                   c=labels_temp, cmap='viridis', alpha=0.7, s=30)\n",
    "    axes[row, col].set_title(f'K={k} Clusters\\n(Silhouette: {silhouette_score(X_scaled, labels_temp):.3f})', \n",
    "                           fontweight='bold')\n",
    "    axes[row, col].set_xlabel('PC1')\n",
    "    axes[row, col].set_ylabel('PC2')\n",
    "    axes[row, col].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç CLUSTER COUNT COMPARISON:\")\n",
    "print(\"Different numbers of clusters reveal different patterns:\")\n",
    "print(\"‚Ä¢ K=2: Broad segmentation (e.g., wealthy vs economy)\")\n",
    "print(\"‚Ä¢ K=3: More nuanced passenger types\")\n",
    "print(\"‚Ä¢ K=4-5: Fine-grained segments, may capture special cases\")\n",
    "print(\"‚Ä¢ Choose based on business needs and cluster interpretability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a103a607-f5dc-4e56-aa1c-6e8492849198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"üìä WEEK 8 ASSIGNMENT REPORT: UNSUPERVISED LEARNING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüéØ PROJECT GOALS:\")\n",
    "print(\"‚Ä¢ Discover natural passenger segments using clustering\")\n",
    "print(\"‚Ä¢ Visualize high-dimensional data in 2D using PCA\")\n",
    "print(\"‚Ä¢ Interpret clusters in business context\")\n",
    "\n",
    "print(f\"\\nüìä METHODOLOGY:\")\n",
    "print(f\"‚Ä¢ Features used: {', '.join(features_for_clustering)}\")\n",
    "print(f\"‚Ä¢ Clustering algorithm: K-Means with k={optimal_k}\")\n",
    "print(f\"‚Ä¢ Dimensionality reduction: PCA (2 components)\")\n",
    "print(f\"‚Ä¢ Data preprocessing: Standardization (mean=0, std=1)\")\n",
    "\n",
    "print(f\"\\nüìà RESULTS:\")\n",
    "print(f\"‚Ä¢ Optimal clusters: {optimal_k} (based on silhouette analysis)\")\n",
    "print(f\"‚Ä¢ Cluster quality: Silhouette score = {sil_score:.3f}\")\n",
    "print(f\"‚Ä¢ PCA effectiveness: {pca_2d.explained_variance_ratio_.sum()*100:.1f}% variance captured in 2D\")\n",
    "print(f\"‚Ä¢ Cluster sizes: {dict(cluster_counts)}\")\n",
    "\n",
    "print(f\"\\nüîç KEY FINDINGS:\")\n",
    "print(\"1. Clear passenger segments emerged from the data\")\n",
    "print(\"2. PCA successfully visualized clusters in 2D space\")\n",
    "print(\"3. Features like Fare and Pclass strongly influence clustering\")\n",
    "print(\"4. Survival rates vary significantly between clusters\")\n",
    "\n",
    "print(f\"\\nüí° BUSINESS INSIGHTS:\")\n",
    "print(\"‚Ä¢ Passenger base can be segmented into meaningful groups\")\n",
    "print(\"‚Ä¢ Different segments had different survival probabilities\")\n",
    "print(\"‚Ä¢ Clustering reveals patterns not obvious in supervised analysis\")\n",
    "print(\"‚Ä¢ Useful for understanding passenger demographics and behavior\")\n",
    "\n",
    "print(f\"\\nüöÄ RECOMMENDATIONS:\")\n",
    "print(\"1. Use clusters for targeted historical analysis\")\n",
    "print(\"2. Consider cluster membership as features in supervised models\")\n",
    "print(\"3. Explore other clustering algorithms (DBSCAN, Hierarchical)\")\n",
    "print(\"4. Apply similar analysis to other historical datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c48358-e3c2-4c79-9e0d-478ee74fe872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib   # ‚úÖ Add this line\n",
    "\n",
    "# Save clustering results                      \n",
    "clustering_results = {\n",
    "    'optimal_k': optimal_k,\n",
    "    'silhouette_score': sil_score,\n",
    "    'cluster_distribution': cluster_counts.to_dict(),\n",
    "    'features_used': features_for_clustering,\n",
    "    'pca_variance_explained': pca_2d.explained_variance_ratio_.sum(),\n",
    "    'cluster_interpretation': {}\n",
    "}\n",
    "\n",
    "# Add cluster interpretations\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = X_clustered[X_clustered['Cluster'] == cluster]\n",
    "    clustering_results['cluster_interpretation'][f'cluster_{cluster}'] = {\n",
    "        'size': len(cluster_data),\n",
    "        'age_mean': cluster_data['Age'].mean(),\n",
    "        'fare_mean': cluster_data['Fare'].mean(),\n",
    "        'pclass_mean': cluster_data['Pclass'].mean(),\n",
    "        'family_size_mean': (cluster_data['SibSp'] + cluster_data['Parch']).mean(),\n",
    "        'survival_rate': df_clustered[df_clustered['Cluster'] == cluster]['Survived'].mean()\n",
    "    }\n",
    "\n",
    "# Save results and models\n",
    "with open('clustering_results.json', 'w') as f:\n",
    "    json.dump(clustering_results, f, indent=2)\n",
    "\n",
    "df_clustered.to_csv('titanic_clustered.csv', index=False)\n",
    "\n",
    "joblib.dump(kmeans, 'kmeans_cluster_model.pkl')\n",
    "joblib.dump(pca_2d, 'pca_model.pkl')\n",
    "joblib.dump(scaler, 'feature_scaler.pkl')\n",
    "\n",
    "print(\"üíæ RESULTS AND MODELS SAVED:\")\n",
    "print(\" - 'clustering_results.json' (comprehensive results)\")\n",
    "print(\" - 'titanic_clustered.csv' (dataset with cluster labels)\")\n",
    "print(\" - 'kmeans_cluster_model.pkl' (trained clustering model)\")\n",
    "print(\" - 'pca_model.pkl' (trained PCA model)\")\n",
    "print(\" - 'feature_scaler.pkl' (feature scaler)\")\n",
    "print(f\"\\nüìÅ Save this notebook as 'week8_unsupervised_learning.ipynb'\")\n",
    "print(\"üöÄ Upload to GitHub to complete Week 8!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
