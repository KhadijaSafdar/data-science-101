{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc50626-bf42-425e-b9f3-5a4593b6900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 6: Supervised Learning - Classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up visualization style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Week 6 Classification Environment Ready!\")\n",
    "\n",
    "# Load your cleaned dataset\n",
    "df = pd.read_csv('titanic_cleaned.csv')\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nColumns available:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b6caa-0a05-40e5-a6eb-daabd36c853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DATASET OVERVIEW FOR CLASSIFICATION ANALYSIS ===\")\n",
    "\n",
    "# Display basic information\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "target_distribution = df['Survived'].value_counts()\n",
    "print(target_distribution)\n",
    "print(f\"Survival rate: {(df['Survived'].mean() * 100):.1f}%\")\n",
    "\n",
    "# Check data types and missing values\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f0ec82-27c2-4599-9f81-3b797434246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PREPARING FOR CLASSIFICATION ===\")\n",
    "\n",
    "\"\"\"\n",
    "For Titanic dataset, the natural classification problem is:\n",
    "Predict Survival (0 = Did not survive, 1 = Survived)\n",
    "\n",
    "We'll use features that are available BEFORE the event (not like 'Survived' in regression)\n",
    "\"\"\"\n",
    "\n",
    "# Select features that would be known before the Titanic sank\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "target_variable = 'Survived'\n",
    "\n",
    "print(f\"üéØ CLASSIFICATION PROBLEM: Predict {target_variable}\")\n",
    "print(f\"Features: {', '.join(features)}\")\n",
    "\n",
    "# Prepare feature matrix X\n",
    "X = df[features].copy()\n",
    "\n",
    "# Handle categorical variables (encode them)\n",
    "print(\"\\nüîß Preprocessing categorical variables...\")\n",
    "\n",
    "# Encode 'Sex' column (male=0, female=1)\n",
    "X['Sex'] = X['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Encode 'Embarked' column (one-hot encoding)\n",
    "embarked_encoded = pd.get_dummies(X['Embarked'], prefix='Embarked')\n",
    "X = pd.concat([X, embarked_encoded], axis=1)\n",
    "X = X.drop('Embarked', axis=1)\n",
    "\n",
    "print(\"Updated features after encoding:\")\n",
    "print(X.columns.tolist())\n",
    "\n",
    "# Target variable\n",
    "y = df[target_variable]\n",
    "\n",
    "print(f\"\\nüìä Final dataset shape:\")\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "\n",
    "# Handle any missing values\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    X = X.fillna(X.median())\n",
    "    print(\"Filled missing values with median\")\n",
    "\n",
    "print(f\"Missing values after cleaning: {X.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aca900f-5301-4d78-be4f-5dda7214c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== TRAIN-TEST SPLIT ===\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% for testing, 80% for training\n",
    "    random_state=42,    # For reproducible results\n",
    "    stratify=y          # Maintain same class distribution in both sets\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")\n",
    "\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(f\"\\nClass distribution in testing set:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ada799-bb09-4ad5-b680-ff9a2c1e2c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DECISION TREE CLASSIFIER ===\")\n",
    "\n",
    "# Create and train Decision Tree\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=3,        # Limit tree depth to prevent overfitting\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Decision Tree model trained successfully!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy:.3f} ({dt_accuracy*100:.1f}%)\")\n",
    "\n",
    "# Feature importance\n",
    "dt_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': dt_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nüìä Decision Tree Feature Importance:\")\n",
    "display(dt_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd16d0b-c087-47ab-a227-8638e16a76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DECISION TREE VISUALIZATION ===\")\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dt_model, \n",
    "          feature_names=X.columns,\n",
    "          class_names=['Not Survived', 'Survived'],\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=12)\n",
    "\n",
    "plt.title('Decision Tree for Titanic Survival Prediction', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç Decision Tree Interpretation:\")\n",
    "print(\"‚Ä¢ Each node shows the decision rule\")\n",
    "print(\"‚Ä¢ Color intensity shows class probability\")\n",
    "print(\"‚Ä¢ Leaf nodes show final predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025dd6a8-959f-4fcd-bcb8-8fba598efdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== RANDOM FOREST CLASSIFIER ===\")\n",
    "\n",
    "# Create and train Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,   # Number of trees in the forest\n",
    "    max_depth=5,        # Limit depth of each tree\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Random Forest model trained successfully!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.3f} ({rf_accuracy*100:.1f}%)\")\n",
    "\n",
    "# Feature importance\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nüìä Random Forest Feature Importance:\")\n",
    "display(rf_importance)\n",
    "\n",
    "# Compare with Decision Tree\n",
    "print(f\"\\nüìà ACCURACY COMPARISON (Class Task):\")\n",
    "print(f\"Decision Tree: {dt_accuracy:.3f} ({dt_accuracy*100:.1f}%)\")\n",
    "print(f\"Random Forest: {rf_accuracy:.3f} ({rf_accuracy*100:.1f}%)\")\n",
    "\n",
    "if rf_accuracy > dt_accuracy:\n",
    "    improvement = ((rf_accuracy - dt_accuracy) / dt_accuracy) * 100\n",
    "    print(f\"‚úÖ Random Forest improves accuracy by {improvement:.1f}%\")\n",
    "else:\n",
    "    print(\"‚ùå Decision Tree performs better in this case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8316bb-957c-446e-b7c5-afb368599906",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== LOGISTIC REGRESSION ===\")\n",
    "\n",
    "# Create and train Logistic Regression\n",
    "lr_model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000  # Increase iterations for convergence\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Logistic Regression model trained successfully!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy:.3f} ({lr_accuracy*100:.1f}%)\")\n",
    "\n",
    "# Get probability predictions\n",
    "y_prob_lr = lr_model.predict_proba(X_test)[:, 1]  # Probability of survival\n",
    "\n",
    "print(\"\\nüìä Logistic Regression Coefficients:\")\n",
    "lr_coefficients = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'coefficient': lr_model.coef_[0]\n",
    "}).sort_values('coefficient', key=abs, ascending=False)\n",
    "\n",
    "display(lr_coefficients)\n",
    "\n",
    "print(\"\\nüîç Coefficient Interpretation:\")\n",
    "print(\"Positive coefficients increase probability of survival\")\n",
    "print(\"Negative coefficients decrease probability of survival\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54559b7f-a8ce-4b3d-b061-e0ab8c31d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DETAILED MODEL COMPARISON ===\")\n",
    "\n",
    "# Calculate metrics for all models\n",
    "models = {\n",
    "    'Logistic Regression': (y_pred_lr, y_prob_lr),\n",
    "    'Random Forest': (y_pred_rf, rf_model.predict_proba(X_test)[:, 1]),\n",
    "    'Decision Tree': (y_pred_dt, dt_model.predict_proba(X_test)[:, 1])\n",
    "}\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for model_name, (predictions, probabilities) in models.items():\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    # Additional metrics from classification report\n",
    "    report = classification_report(y_test, predictions, output_dict=True)\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision_0': report['0']['precision'],  # Not survived\n",
    "        'Recall_0': report['0']['recall'],\n",
    "        'Precision_1': report['1']['precision'],  # Survived\n",
    "        'Recall_1': report['1']['recall'],\n",
    "        'F1_Score': report['macro avg']['f1-score']\n",
    "    })\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "comparison_df = comparison_df.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"üìä COMPREHENSIVE MODEL COMPARISON:\")\n",
    "display(comparison_df.round(3))\n",
    "\n",
    "# Find best model\n",
    "best_model = comparison_df.iloc[0]\n",
    "print(f\"\\nüéØ BEST PERFORMING MODEL: {best_model['Model']}\")\n",
    "print(f\"   Accuracy: {best_model['Accuracy']:.3f} ({best_model['Accuracy']*100:.1f}%)\")\n",
    "print(f\"   F1 Score: {best_model['F1_Score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2716e13a-001a-41bf-a18a-3169f1f27e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== MODEL PERFORMANCE VISUALIZATION ===\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Accuracy Comparison\n",
    "models_names = comparison_df['Model']\n",
    "accuracies = comparison_df['Accuracy']\n",
    "\n",
    "bars = axes[0, 0].bar(models_names, accuracies, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[0, 0].set_title('Model Accuracy Comparison', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].set_ylim(0, 1)\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                   f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 2: Feature Importance Comparison\n",
    "feature_importance_comparison = pd.DataFrame({\n",
    "    'Logistic Regression': abs(lr_model.coef_[0]),\n",
    "    'Random Forest': rf_model.feature_importances_,\n",
    "    'Decision Tree': dt_model.feature_importances_\n",
    "}, index=X.columns)\n",
    "\n",
    "# Normalize for better comparison\n",
    "feature_importance_comparison = feature_importance_comparison.div(feature_importance_comparison.sum(axis=0), axis=1)\n",
    "\n",
    "feature_importance_comparison.plot(kind='bar', ax=axes[0, 1], color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[0, 1].set_title('Feature Importance Comparison', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Normalized Importance')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Plot 3: Confusion Matrix for Best Model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    best_predictions = y_pred_lr\n",
    "elif best_model_name == 'Random Forest':\n",
    "    best_predictions = y_pred_rf\n",
    "else:\n",
    "    best_predictions = y_pred_dt\n",
    "\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0],\n",
    "            xticklabels=['Not Survived', 'Survived'],\n",
    "            yticklabels=['Not Survived', 'Survived'])\n",
    "axes[1, 0].set_title(f'Confusion Matrix - {best_model_name}', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Predicted')\n",
    "axes[1, 0].set_ylabel('Actual')\n",
    "\n",
    "# Plot 4: Precision-Recall Comparison\n",
    "precision_survived = comparison_df['Precision_1'].values\n",
    "recall_survived = comparison_df['Recall_1'].values\n",
    "\n",
    "for i, model in enumerate(models_names):\n",
    "    axes[1, 1].scatter(recall_survived[i], precision_survived[i], s=100, label=model)\n",
    "    axes[1, 1].text(recall_survived[i] + 0.01, precision_survived[i] + 0.01, model, fontsize=9)\n",
    "\n",
    "axes[1, 1].set_xlabel('Recall (Survived)')\n",
    "axes[1, 1].set_ylabel('Precision (Survived)')\n",
    "axes[1, 1].set_title('Precision-Recall Comparison', fontweight='bold')\n",
    "axes[1, 1].set_xlim(0, 1)\n",
    "axes[1, 1].set_ylim(0, 1)\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7701f7cd-69b8-4168-8774-2e4c8c2a88ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== MODEL INTERPRETATION AND BUSINESS INSIGHTS ===\")\n",
    "\n",
    "print(\"üîç KEY INSIGHTS FROM CLASSIFICATION MODELS:\")\n",
    "\n",
    "print(f\"\\n1. BEST PERFORMING MODEL: {best_model['Model']}\")\n",
    "print(f\"   ‚Ä¢ Accuracy: {best_model['Accuracy']:.1%}\")\n",
    "print(f\"   ‚Ä¢ Can correctly predict survival for {best_model['Accuracy']:.1%} of passengers\")\n",
    "\n",
    "print(f\"\\n2. MOST IMPORTANT FEATURES:\")\n",
    "print(\"   Across all models, these features consistently matter:\")\n",
    "top_features = rf_importance.head(3)\n",
    "for _, row in top_features.iterrows():\n",
    "    print(f\"   ‚Ä¢ {row['feature']}: {row['importance']:.3f} importance\")\n",
    "\n",
    "print(f\"\\n3. PRACTICAL IMPLICATIONS:\")\n",
    "print(\"   ‚Ä¢ Gender (Sex) is the strongest predictor of survival\")\n",
    "print(\"   ‚Ä¢ Passenger class (Pclass) significantly impacts survival chances\")\n",
    "print(\"   ‚Ä¢ Fare paid correlates with survival probability\")\n",
    "print(\"   ‚Ä¢ Age has moderate influence on survival\")\n",
    "\n",
    "print(f\"\\n4. MODEL RELIABILITY:\")\n",
    "print(f\"   ‚Ä¢ All models achieve > {comparison_df['Accuracy'].min()*100:.1f}% accuracy\")\n",
    "print(f\"   ‚Ä¢ Significant improvement over guessing ({y_test.mean()*100:.1f}% baseline)\")\n",
    "\n",
    "# Calculate baseline (predict majority class)\n",
    "baseline_accuracy = max(y_test.mean(), 1 - y_test.mean())\n",
    "improvement = ((best_model['Accuracy'] - baseline_accuracy) / baseline_accuracy) * 100\n",
    "\n",
    "print(f\"   ‚Ä¢ Models improve over baseline by {improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cdfa23-b80c-41fd-bba7-5c9e1a42cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PROBABILITY ANALYSIS ===\")\n",
    "\n",
    "# Analyze probability distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot probability distributions for survived vs not survived\n",
    "for i, (model_name, (predictions, probabilities)) in enumerate(models.items()):\n",
    "    survived_probs = probabilities[y_test == 1]\n",
    "    not_survived_probs = probabilities[y_test == 0]\n",
    "    \n",
    "    axes[0].hist(survived_probs, bins=20, alpha=0.5, label=f'{model_name} - Survived')\n",
    "    axes[1].hist(not_survived_probs, bins=20, alpha=0.5, label=f'{model_name} - Not Survived')\n",
    "\n",
    "axes[0].set_xlabel('Predicted Probability of Survival')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Probability Distribution - Actual Survivors')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('Predicted Probability of Survival')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Probability Distribution - Actual Non-Survivors')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç Probability Analysis Insights:\")\n",
    "print(\"‚Ä¢ Good models show high probabilities for correct classes\")\n",
    "print(\"‚Ä¢ Overlapping distributions indicate classification uncertainty\")\n",
    "print(\"‚Ä¢ Well-calibrated models separate the classes clearly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0071a282-44c0-4cdf-83fb-a8c05e8e3529",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"üìä WEEK 6 ASSIGNMENT REPORT: CLASSIFICATION ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüéØ CLASSIFICATION PROBLEM:\")\n",
    "print(f\"Target Variable: {target_variable} (Binary Classification)\")\n",
    "print(f\"Features: {', '.join(features)}\")\n",
    "print(f\"Dataset: Titanic ({df.shape[0]} passengers)\")\n",
    "\n",
    "print(f\"\\nüìà MODEL PERFORMANCE SUMMARY:\")\n",
    "print(\"Algorithm          Accuracy    Precision   Recall     F1-Score\")\n",
    "print(\"-\" * 60)\n",
    "for _, row in comparison_df.iterrows():\n",
    "    print(f\"{row['Model']:18} {row['Accuracy']:.3f}      {row['Precision_1']:.3f}      {row['Recall_1']:.3f}      {row['F1_Score']:.3f}\")\n",
    "\n",
    "print(f\"\\nüîç KEY FINDINGS:\")\n",
    "print(f\"1. Best Model: {best_model['Model']} with {best_model['Accuracy']:.1%} accuracy\")\n",
    "print(f\"2. Most Important Feature: {rf_importance.iloc[0]['feature']}\")\n",
    "print(f\"3. All models significantly beat baseline guessing ({baseline_accuracy:.1%})\")\n",
    "\n",
    "print(f\"\\nüí° BUSINESS INSIGHTS:\")\n",
    "print(\"‚Ä¢ Gender is the strongest survival predictor ('women and children first')\")\n",
    "print(\"‚Ä¢ Higher socioeconomic status (Pclass, Fare) improves survival chances\")\n",
    "print(\"‚Ä¢ Traveling with family has complex effects on survival probability\")\n",
    "\n",
    "print(f\"\\nüöÄ RECOMMENDATIONS:\")\n",
    "print(\"1. Random Forest provides good balance of accuracy and interpretability\")\n",
    "print(\"2. Consider feature engineering for better performance\")\n",
    "print(\"3. Collect additional relevant features if possible\")\n",
    "\n",
    "print(f\"\\nüìö LEARNING OUTCOMES:\")\n",
    "print(\"‚úÖ Implemented multiple classification algorithms\")\n",
    "print(\"‚úÖ Understood difference between regression and classification\")\n",
    "print(\"‚úÖ Compared model performance using multiple metrics\")\n",
    "print(\"‚úÖ Interpreted feature importance and model decisions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1a850-5cec-4218-89ed-52a8ebad8fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained models for future use\n",
    "import joblib\n",
    "\n",
    "# Save all models\n",
    "joblib.dump(lr_model, 'logistic_regression_model.pkl')\n",
    "joblib.dump(rf_model, 'random_forest_model.pkl')\n",
    "joblib.dump(dt_model, 'decision_tree_model.pkl')\n",
    "\n",
    "# Save predictions and comparison results\n",
    "predictions_comparison = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Logistic_Regression': y_pred_lr,\n",
    "    'Random_Forest': y_pred_rf,\n",
    "    'Decision_Tree': y_pred_dt\n",
    "})\n",
    "\n",
    "predictions_comparison.to_csv('classification_predictions.csv', index=False)\n",
    "comparison_df.to_csv('model_comparison_results.csv', index=False)\n",
    "\n",
    "print(\"üíæ MODELS AND RESULTS SAVED:\")\n",
    "print(\" - 'logistic_regression_model.pkl'\")\n",
    "print(\" - 'random_forest_model.pkl'\")\n",
    "print(\" - 'decision_tree_model.pkl'\")\n",
    "print(\" - 'classification_predictions.csv'\")\n",
    "print(\" - 'model_comparison_results.csv'\")\n",
    "print(f\"\\nüìÅ Save this notebook as 'week6_classification_analysis.ipynb'\")\n",
    "print(\"üöÄ Upload to GitHub to complete Assignment 6!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
